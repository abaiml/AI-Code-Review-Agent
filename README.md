# ğŸ¤– AI Code Review Agent

An intelligent code review and improvement tool that uses **Google Gemini AI** to automatically improve code readability, performance, and quality. It also tests original and improved code for correctness and reports metrics like **Maintainability Index** and **Cyclomatic Complexity**.

---

## ğŸš€ Features

- âœ… Automatically reviews and improves code (Python, C++, JavaScript, etc.)
- ğŸ“Š Analyzes code quality before and after AI improvement
- ğŸ§ª Testing Support: Uses Piston API for basic execution and language-specific frameworks (e.g., Pytest, JUnit, Google Test) for deeper correctness checks
- ğŸ“„ Generates a detailed `report.md` with summary of improvements
- ğŸ“ Supports reviewing entire codebases or single files
- ğŸ” Modular design for extension (e.g., add performance or security focus)

---

## ğŸ“ Project Structure

```
AI-Code-Review-Agent/
â”œâ”€â”€ main.py                  # CLI entry point
â”œâ”€â”€ ai_agent.py              # Gemini AI integration
â”œâ”€â”€ utils.py                 # File processing & report generation
â”œâ”€â”€ metrics.py               # Code quality analysis (Radon + Lizard)
â”œâ”€â”€ test_runner.py           # Code execution via Piston API
â”œâ”€â”€ requirements.txt         # Dependencies
```

---

## ğŸ› ï¸ Setup & Installation

1. **Clone the repo:**
   ```bash
   git clone https://github.com/abaiml/AI-Code-Review-Agent.git
   cd AI-Code-Review-Agent
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set your Gemini API key:**
   Create a `.env` file in the root with:
   ```env
   GEMINI_API_KEY=your_gemini_api_key_here
   ```

---

## ğŸ“¦ Usage

```bash
python main.py --input ./sample --output ./improved_code --focus readability
```

### Arguments:

| Flag       | Description                                           |
|------------|-------------------------------------------------------|
| `--input`  | Folder containing source code to review               |
| `--output` | Folder where improved code and reports will be saved |
| `--focus`  | Review focus area (`readability`, `performance`, etc.) |

ğŸ“ **Note:** You can choose any `--input` and `--output` folder paths. The program runs relative to the location of `main.py`.

ğŸ§ª **Test Execution Modes:**
- **Basic Check:** Uses [Piston API](https://github.com/engineer-man/piston) to run code and verify it executes without errors
- **Deeper Validation:** Automatically uses appropriate frameworks based on language:
  - Python â†’ Pytest  
  - C++ â†’ Google Test  
  - JavaScript â†’ Jest or Mocha  
  - Java â†’ JUnit  
  - C# â†’ xUnit  
  - Go â†’ GoTest

---

## ğŸ“‹ Output

After running the tool:

- Improved code is saved in `./improved_code`
- A report is generated at `./improved_code/report.md` summarizing:
  - Summary of AI changes with line references
  - âœ… or âŒ test results (before & after)
  - Maintainability Index & Cyclomatic Complexity metrics

---

## âœ… Example Report Snippet

```markdown
## sample/app.py
**Focus**: readability

```python
def main():
    """
    Sorts a list of numbers in ascending order and prints the sorted list.
    """
    numbers = [10, 32, 5, 1, 6, 16, 4, 6, 100]
    numbers.sort()
    print(numbers)
```

**Summary of Changes:**
- Line 3: Added docstring
- Line 6: Renamed variable `data` to `numbers`

**Test Results**
- Before Improvement: âœ… Passed
- After Improvement: âœ… Passed

**Code Quality Metrics:**
- Maintainability Index: 78.02 â 100.00
- Avg. Cyclomatic Complexity: 1.00 â 1.00
```

---

## ğŸ“Œ Future Enhancements

- [ ] Add security and performance review focus modes
- [ ] Web UI for uploading files and viewing reports
- [ ] Integrate structured multi-language testing by automatically selecting appropriate frameworks
- [ ] Add more languages support (PHP, TS, Ruby)
- [ ] Generate before/after diffs visually


---

## ğŸ“ƒ License

MIT License
